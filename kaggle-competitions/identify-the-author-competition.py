# -*- coding: utf-8 -*-
"""good_notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xk80Al-_Q42V1nDdL58EdlreQnDXXQI4
"""

# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE
# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.
import kagglehub
kagglehub.login()

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

identify_the_author_path = kagglehub.competition_download('identify-the-author')

print('Data source import complete.')

!pip install benepar nrclex

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import benepar # Import benepar module
from benepar.spacy_plugin import BeneparComponent

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import re
import nltk
import numpy as np
from collections import Counter,defaultdict
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer
import spacy
from tqdm.notebook import tqdm
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from textblob import TextBlob
from nrclex import NRCLex
from nltk import sent_tokenize

nlp_basic = spacy.load("en_core_web_sm", disable=["ner", "parser"])
nlp_basic.add_pipe("sentencizer")
nltk.download("vader_lexicon")

vader = SentimentIntensityAnalyzer()


warnings.filterwarnings("ignore", category=FutureWarning, module='seaborn')

nltk.download('stopwords')
nltk.download('punkt')
try:
    nltk.data.find('tokenizers/punkt_tab/english/')
except LookupError:
    nltk.download('punkt_tab')
benepar.download('benepar_en3')
nlp_benepar = spacy.load("en_core_web_sm")
nlp_benepar.add_pipe("sentencizer")
nlp_benepar.add_pipe("benepar", config={"model": "benepar_en3"})

def extract_stylistic_rhetoric_features(df):
    def repetition_ratio(text):
        tokens = text.lower().split()
        return sum(1 for i in range(1, len(tokens)) if tokens[i] == tokens[i-1]) / len(tokens) if len(tokens) > 1 else 0

    def anaphora_count(text):
        sents = re.split(r'[.!?]', text.lower())
        sents = [s.strip().split() for s in sents if len(s.strip()) > 0]
        return sum(1 for i in range(1, len(sents)) if len(sents[i]) > 0 and len(sents[i-1]) > 0 and sents[i][0] == sents[i-1][0]) if len(sents) > 1 else 0

    def epiphora_count(text):
        sents = re.split(r'[.!?]', text.lower())
        sents = [s.strip().split() for s in sents if len(s.strip()) > 0]
        return sum(1 for i in range(1, len(sents)) if len(sents[i]) > 0 and len(sents[i-1]) > 0 and sents[i][-1] == sents[i-1][-1]) if len(sents) > 1 else 0

    def alliteration_score(text):
        tokens = [w for w in re.findall(r'\b\w+', text.lower())]
        return sum(1 for i in range(1, len(tokens)) if tokens[i][0] == tokens[i-1][0]) / len(tokens) if len(tokens) > 1 else 0

    def sound_score(text):
        vowels = set('aeiou')
        tokens = re.findall(r'\b\w+\b', text.lower())
        v_count = sum(sum(1 for c in w if c in vowels) for w in tokens)
        c_count = sum(sum(1 for c in w if c.isalpha() and c not in vowels) for w in tokens)
        return c_count / (v_count + 1)  # evită împărțirea la 0

    df['repetition_ratio'] = df['text'].apply(repetition_ratio)
    df['anaphora_count'] = df['text'].apply(anaphora_count)
    df['epiphora_count'] = df['text'].apply(epiphora_count)
    df['alliteration_score'] = df['text'].apply(alliteration_score)
    df['sound_score'] = df['text'].apply(sound_score)

    return df

def extract_emotional_features(df):
    emotion_keys = ["sadness", "fear", "anger", "trust", "joy"]
    records = []

    for text in tqdm(df["text"], desc="Etapa 4.1: Emoții + Sentiment"):
        try:
            blob = TextBlob(text)
            sentences = sent_tokenize(text)
            vader_scores = vader.polarity_scores(text)

            polarity = blob.sentiment.polarity
            subjectivity = blob.sentiment.subjectivity
            vader_compound = vader_scores["compound"]

            sent_pols = [TextBlob(s).sentiment.polarity for s in sentences if s.strip()]
            sentiment_var = np.std(sent_pols) if sent_pols else 0

            emo = NRCLex(text)
            emo_scores = {k: 0 for k in emotion_keys}
            emo_dist = emo.raw_emotion_scores
            total = sum(emo_dist.values())
            if total > 0:
                for k in emotion_keys:
                    emo_scores[k] = emo_dist.get(k, 0) / total

            records.append({
                "polarity": polarity,
                "subjectivity": subjectivity,
                "vader_compound": vader_compound,
                "sentiment_variability": sentiment_var,
                **emo_scores
            })

        except Exception:
            records.append({
                "polarity": 0, "subjectivity": 0, "vader_compound": 0,
                "sentiment_variability": 0,
                **{k: 0 for k in emotion_keys}
            })

    emo_df = pd.DataFrame(records)
    return pd.concat([df.reset_index(drop=True), emo_df], axis=1)

archaic_words = {
    "thee", "thy", "thou", "ye", "thine", "thyself", "thou'st",
    "hast", "hadst", "dost", "didst", "wilt", "shalt", "art", "wert", "wouldst",
    "shouldst", "mightst", "couldst", "mayest", "must needs", "knowest", "goest",
    "comest", "sayest", "thinkest", "givest", "takest", "bringest",
    "quoth", "methinks", "peradventure", "verily", "forsooth", "alack",
    "alas", "anon", "ere", "hie", "hither", "thither", "whither", "whence", "wherefore",
    "oft", "aught", "naught", "lest", "betwixt", "bespeak", "behold", "beseech",
    "bid", "hark", "prithee", "fain", "maketh", "leadeth", "speaketh", "bringeth",
    "cometh", "goeth", "doth", "saith", "liveth", "believeth", "departeth",
    "hearken", "abideth", "cleaveth", "smite", "smiteth", "slayeth",

    "afore", "amongst", "amidst", "nigh", "ofttimes", "herein", "therein", "herewith",
    "thence", "thenceforth", "thereto", "thereupon", "hereupon", "wherein",
    "whereto", "whereupon", "unto", "unto thee", "thou art", "henceforth", "beseemeth",

    "nay", "ne'er", "e'en", "nary", "withouten", "withal", "yea",

    "redeemeth", "delivereth", "blesseth", "beareth", "forsaketh", "raiseth", "gladdeneth",
    "judgeth", "abominable", "tribulation", "suffereth", "falleth", "proclaimeth", "bestoweth",

    "gan", "gadzooks", "zounds", "marry", "ofttimes", "troth", "dree", "yclept",

    "phantasm", "spectre", "countenance", "dismal", "ghast", "throb", "visage", "shade", "moor",
    "eldritch", "raven", "gloom", "sepulchre", "dirge", "wither", "wan", "woe", "morrow", "tempest",

    "dungeon", "lament", "banish", "forsaken", "lamentation", "grim", "wailing", "accursed",
    "unhallowed", "maiden", "chamber", "slumber", "enchanted", "cavern", "gory", "slain", "pale"
}


horror_words = {
    "madness", "eldritch", "unnameable", "shudder", "abyss", "void", "chaos",
    "nightmare", "nameless", "blasphemous", "unspeakable", "dread", "shambling",
    "tentacle", "fiend", "antiquarian", "cyclopean", "lurking", "shoggoth", "cthulhu",

    "terror", "fear", "fright", "horror", "panic", "dismay", "phobia", "revulsion",
    "shock", "apprehension", "agony", "anguish", "alarm", "nausea", "trembling", "delirium",

    "grotesque", "gruesome", "ghastly", "gory", "bloody", "slaughter", "decomposing",
    "rotting", "oozing", "pus", "fetid", "stench", "maimed", "mutilated", "disfigured",

    "possessed", "ritual", "cult", "cursed", "accursed", "hexed", "exorcism", "specter",
    "apparition", "phantom", "wraith", "shade", "ghost", "haunting", "poltergeist",

    "decay", "damp", "gloom", "desolation", "abandoned", "crumbling", "ruin", "forgotten",
    "despair", "withered", "dim", "dark", "mist", "fog", "storm", "grave", "sepulcher", "crypt",
    "catacomb", "dungeon", "lair", "tomb", "cavern",

    "insanity", "delusion", "hallucination", "torment", "affliction", "wretched",
    "anguish", "doom", "curse", "demonic", "devilish", "monstrous", "evil", "malevolent",
    "malignant", "abhorrent", "horrid", "macabre", "depraved", "twisted", "unholy", "damned",

    "scream", "wail", "moan", "howl", "shriek", "gasp", "cower", "crawl", "choke", "crush",
    "slice", "stab", "bleed", "devour", "mutate", "consume", "rip", "rend", "slither", "lurk",

    "beyond", "ancient", "forgotten", "primordial", "elders", "insignificance", "futility",
    "vastness", "incomprehensible", "alien", "interdimensional", "infinite", "cyclopean",
    "slumbering", "unseen", "waking", "depths", "bottomless", "nameless cults"
}


romantic_words = {
    "love", "heart", "soul", "joy", "affection", "emotion", "desire", "tender", "grace",
    "embrace", "passion", "devotion", "adore", "fond", "romance", "longing", "yearn",
    "intimacy", "delight", "sweet", "darling", "happiness", "pleasure", "gentle",
    "rapture", "ardor", "faith", "sentiment", "warmth",

    "spring", "light", "breeze", "blossom", "meadow", "dew", "stream", "sunlight",
    "bloom", "flower", "butterfly", "petal", "dawn", "sunrise", "moonlight", "stars",
    "twilight", "birds", "river", "willow", "mist", "rain", "garden", "rose",
    "sky", "windswept", "leaves", "morning", "evening",

    "hope", "dream", "eternity", "heaven", "radiant", "divine", "purity", "truth",
    "beauty", "sublime", "sacred", "destiny", "serenity", "innocence", "virtue",
    "sincerity", "compassion", "solace", "enchantment", "freedom", "inspiration",
    "peace", "contemplation", "harmony", "ethereal", "tranquility",
    "kiss", "beloved", "dearest", "sweetheart", "tenderness", "adoration", "friendship",
    "trust", "connection", "bond", "caress", "fondness", "closeness", "belong", "soulmate",

    "melancholy", "reflection", "emotion", "feeling", "sentimental", "soft", "gentleness",
    "nostalgia", "conscience", "awakening", "vulnerability", "delicacy", "subtlety", "whisper",
    "awe", "muse", "solitude", "imagination", "consolation", "poetry", "tremble",

    "fragrance", "glow", "radiance", "infinite", "lightness", "bliss", "hopeful", "despair",
    "spirit", "lilies", "violets", "ivy", "nymph", "sprite", "cypress", "veil", "gossamer",
    "halo", "lustre", "sparkle", "starlight", "haze", "lullaby", "aroma", "flame"
}

from sklearn.feature_extraction.text import TfidfVectorizer

def build_semantic_vocabulars(df, top_n=50):

    def get_top_words(texts, n=top_n):
        tfidf = TfidfVectorizer(stop_words='english', max_features=3000)
        X = tfidf.fit_transform(texts)
        scores = X.sum(axis=0).A1
        words = tfidf.get_feature_names_out()
        return [w for w, _ in sorted(zip(words, scores), key=lambda x: -x[1])[:n]]

    eap_vocab = get_top_words(df[df.author == 'EAP']['text'], n=top_n)
    hpl_vocab = get_top_words(df[df.author == 'HPL']['text'], n=top_n)
    mws_vocab = get_top_words(df[df.author == 'MWS']['text'], n=top_n)

    eap_set = set(eap_vocab) - set(hpl_vocab) - set(mws_vocab)
    hpl_set = set(hpl_vocab) - set(eap_vocab) - set(mws_vocab)
    mws_set = set(mws_vocab) - set(eap_vocab) - set(hpl_vocab)

    semantic_vocabulars = {
        'archaic': archaic_words | eap_set,
        'horror': horror_words | hpl_set,
        'romantic': romantic_words | mws_set
    }

    return semantic_vocabulars

def extract_semantic_features(df, vocabulars):
    def vocab_hit(text, vocab):
        tokens = text.lower().split()
        return sum(1 for word in tokens if word in vocab)

    df['archaic_count'] = df['text'].apply(lambda x: vocab_hit(x, vocabulars['archaic']))
    df['horror_count'] = df['text'].apply(lambda x: vocab_hit(x, vocabulars['horror']))
    df['romantic_count'] = df['text'].apply(lambda x: vocab_hit(x, vocabulars['romantic']))

    df['archaic_density'] = df['archaic_count'] / df['word_count'].replace(0, 1)
    df['horror_density'] = df['horror_count'] / df['word_count'].replace(0, 1)
    df['romantic_density'] = df['romantic_count'] / df['word_count'].replace(0, 1)

    return df

def extract_pos_features(df, nlp, batch_size=64):
    results = []
    texts = df['text'].fillna("").astype(str).tolist()

    for doc in tqdm(nlp.pipe(texts, batch_size=batch_size), total=len(texts), desc="POS tagging"):
        token_count = len(doc) or 1

        result = {
            'noun_ratio': sum(1 for t in doc if t.pos_ == 'NOUN') / token_count,
            'verb_ratio': sum(1 for t in doc if t.pos_ == 'VERB') / token_count,
            'adj_ratio': sum(1 for t in doc if t.pos_ == 'ADJ') / token_count,
            'adv_ratio': sum(1 for t in doc if t.pos_ == 'ADV') / token_count,
            'pronoun_ratio': sum(1 for t in doc if t.pos_ == 'PRON') / token_count,
            'prep_ratio': sum(1 for t in doc if t.dep_ == 'prep') / token_count,
            'conj_ratio': sum(1 for t in doc if t.dep_ == 'cc') / token_count,
            'modal_count': sum(1 for t in doc if t.tag_ == 'MD'),
            'aux_verb_count': sum(1 for t in doc if t.dep_ == 'aux')
        }

        results.append(result)

    pos_df = pd.DataFrame(results)
    return pd.concat([df.reset_index(drop=True), pos_df], axis=1)

stop_words = set(stopwords.words('english'))

function_words = set([
    'a', 'an', 'the', 'and', 'but', 'or', 'as', 'if', 'while', 'of', 'at', 'by',
    'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during',
    'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in',
    'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once',
    'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both',
    'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not',
    'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can',
    'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've',
    'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven',
    'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren',
    'won', 'wouldn'
])


def add_length_features(df):
    df['text_len'] = df['text'].str.len()

    df['word_count'] = df['text'].str.split().apply(len)

    df['sentence_count'] = df['text'].apply(lambda x: len(re.findall(r'[.!?]', x)))

    df['words_per_sentence'] = df['word_count'] / df['sentence_count'].replace(0, 1)

    df['unique_word_ratio'] = df['text'].apply(
        lambda x: len(set(x.split())) / len(x.split()) if len(x.split()) > 0 else 0
    )

    return df

def extract_punct_features(text):
    return {
        'comma_count': text.count(','),
        'semicolon_count': text.count(';'),
        'ellipsis_count': text.count('...'),
        'exclamation_count': text.count('!'),
        'punct_count': sum(text.count(p) for p in '.,;:?!\"-()')
    }

def add_punctuation_features(df):
    punct_df = df['text'].apply(extract_punct_features).apply(pd.Series)

    punct_df['text_len'] = df['text_len']
    punct_df['word_count'] = df['word_count'].replace(0, 1)

    punct_df['punct_density'] = punct_df['punct_count'] / punct_df['text_len']
    punct_df['comma_ratio'] = punct_df['comma_count'] / punct_df['word_count']
    punct_df['semicolon_ratio'] = punct_df['semicolon_count'] / punct_df['word_count']
    punct_df['ellipsis_ratio'] = punct_df['ellipsis_count'] / punct_df['word_count']
    punct_df['exclam_ratio'] = punct_df['exclamation_count'] / punct_df['word_count']

    punct_df['expressiveness_score'] = (
        punct_df['comma_ratio'] +
        punct_df['ellipsis_ratio'] +
        punct_df['exclam_ratio']
    )

    selected_cols = [
        'comma_count', 'semicolon_count', 'ellipsis_count',
        'punct_density', 'expressiveness_score'
    ]

    return pd.concat([df, punct_df[selected_cols]], axis=1)

def add_lexical_features(df):
    def compute_lexical(text):
        words = word_tokenize(text)
        lower_words = [w.lower() for w in words]
        word_lengths = [len(w) for w in words]
        freqs = Counter(lower_words)

        total_words = len(words)
        unique_words = len(set(lower_words))

        return pd.Series({
            'long_words_ratio': np.mean([l > 10 for l in word_lengths]) if word_lengths else 0,
            'short_word_ratio': np.mean([1 <= l <= 3 for l in word_lengths]) if word_lengths else 0,
            'hapax_legomena_ratio': sum(1 for w in freqs if freqs[w] == 1) / total_words if total_words else 0,
            'stopword_ratio': np.mean([w in stop_words for w in lower_words]) if total_words else 0,
            'vocabulary_richness': unique_words / np.sqrt(2 * total_words) if total_words else 0,
            'function_word_ratio': np.mean([w in function_words for w in lower_words]) if total_words else 0
        })

    lexical_df = df['text'].apply(compute_lexical)
    return pd.concat([df, lexical_df], axis=1)

def extract_ngram_features(df, word_max_features=8000, char_max_features=6000):

    tfidf_word_vectorizer = TfidfVectorizer(
        sublinear_tf=True,
        strip_accents='unicode',
        analyzer='word',
        token_pattern=r'\b\w+\b',
        stop_words='english',
        ngram_range=(1, 2),
        max_features=word_max_features
    )
    X_tfidf_word = tfidf_word_vectorizer.fit_transform(df['text'])

    tfidf_char_vectorizer = TfidfVectorizer(
        analyzer='char_wb',
        ngram_range=(3, 5),
        max_features=char_max_features
    )
    X_tfidf_char = tfidf_char_vectorizer.fit_transform(df['text'])

    df['starting_unigram'] = df['text'].apply(
        lambda x: x.strip().split()[0].lower() if len(x.strip().split()) > 0 else ''
    )
    start_vec = CountVectorizer()
    X_starting = start_vec.fit_transform(df['starting_unigram'])

    df['trailing_bigram'] = df['text'].apply(
        lambda x: ' '.join(x.strip().split()[-2:]).lower() if len(x.strip().split()) >= 2 else ''
    )
    trail_vec = CountVectorizer()
    X_trailing = trail_vec.fit_transform(df['trailing_bigram'])

    return {
        "X_tfidf_word": X_tfidf_word,
        "X_tfidf_char": X_tfidf_char,
        "X_starting": X_starting,
        "X_trailing": X_trailing,
        "vectorizers": {
            "word_vectorizer": tfidf_word_vectorizer,
            "char_vectorizer": tfidf_char_vectorizer,
            "start_vec": start_vec,
            "trail_vec": trail_vec
        }
    }


df = pd.read_csv(f'{identify_the_author_path}/train/train.csv')
semantic_vocabulars= build_semantic_vocabulars(df)
def extract_all_features(df):
    df = add_length_features(df)
    df = add_punctuation_features(df)
    df = add_lexical_features(df)
    df = extract_semantic_features(df, semantic_vocabulars)
    df = df.drop(columns=['archaic_count', 'horror_count', 'romantic_count'], errors='ignore')
    df['stylo_emotion_interact'] = df['expressiveness_score'] * df['romantic_density']

    df = extract_pos_features(df, nlp_basic)
    df=extract_emotional_features(df)
    df = extract_stylistic_rhetoric_features(df)
    df.drop(columns=[
        "prep_ratio",
        "conj_ratio",
        "mean_tree_depth",
        "subordinate_clause_ratio"
    ], inplace=True, errors="ignore")

    df.drop(columns=['text_len', 'sentence_count', 'aux_verb_count', 'ellipsis_count'], inplace=True, errors='ignore')
    drop_cols = [
    'stylo_emotion_interact',       # mostly zero
    'sentiment_variability',        # flat
    'joy', 'trust', 'anger',        # weak impact
    'function_word_ratio',          # redundant with stopword_ratio
    'punct_density',                # redundant with expressiveness_score
    'modal_count'                   
    ]
    df['has_anaphora'] = (df['anaphora_count'] > 0).astype(int)
    df['has_epiphora'] = (df['epiphora_count'] > 0).astype(int)
    df.drop(columns=['anaphora_count', 'epiphora_count'], inplace=True, errors='ignore')
    df.drop(columns=drop_cols, inplace=True, errors='ignore')

    return df

df=extract_all_features(df)

df_test = pd.read_csv(f'{identify_the_author_path}/test/test.csv')
df_test = extract_all_features(df_test)

import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import log_loss, accuracy_score
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    get_linear_schedule_with_warmup,
    DataCollatorWithPadding
)
from torch.optim import AdamW
from torch.amp import autocast, GradScaler
from tqdm import tqdm

NUM_CLASSES = 3
MAX_LEN = 512
BATCH_SIZE = 32
EPOCHS = 4
SEED = 42
LR = 1.5e-5
SAVE_DIR = "llm_preds"
MODELS = [
    "roberta-large",
    "microsoft/deberta-v3-base",
    "google/electra-base-discriminator",
    "xlm-roberta-large",
    "albert-xxlarge-v2"
]

os.makedirs(SAVE_DIR, exist_ok=True)

df["label"] = LabelEncoder().fit_transform(df["author"])
true_labels = df["label"].values

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class TextDataset(Dataset):
    def __init__(self, texts, labels=None, tokenizer=None):
        self.encodings = tokenizer(texts, truncation=True, padding=False, max_length=MAX_LEN)
        self.labels = labels

    def __len__(self):
        return len(self.encodings["input_ids"])

    def __getitem__(self, idx):
        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}
        if self.labels is not None:
            item["labels"] = torch.tensor(self.labels[idx])
        return item

def train_fn(model, loader, optimizer, scheduler, scaler):
    model.train()
    total_loss = 0
    for batch in tqdm(loader, desc="Training", leave=False):
        batch = {k: v.to(device) for k, v in batch.items()}
        with autocast(device_type="cuda"):
            outputs = model(**batch)
            loss = outputs.loss
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        optimizer.zero_grad()
        scheduler.step()
        total_loss += loss.item()
    return total_loss / len(loader)


def eval_fn(model, loader):
    model.eval()
    probs = []
    with torch.no_grad():
        for batch in tqdm(loader, desc="Evaluating", leave=False):
            batch = {k: v.to(device) for k, v in batch.items() if k != "labels"}
            with autocast(device_type="cuda"):
                outputs = model(**batch)
                logits = outputs.logits
                probs.append(torch.softmax(logits, dim=1).cpu().numpy())
    return np.vstack(probs)


final_test_preds = np.zeros((len(df_test), NUM_CLASSES))

for model_name in MODELS:
    print(f"\n Training model: {model_name}")

    tokenizer = AutoTokenizer.from_pretrained(model_name)
    collator = DataCollatorWithPadding(tokenizer=tokenizer)
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)

    oof_preds = np.zeros((len(df), NUM_CLASSES))
    test_preds = np.zeros((len(df_test), NUM_CLASSES))

    for fold, (train_idx, val_idx) in enumerate(skf.split(df["text"], df["label"])):
        print(f"\n--- Fold {fold + 1} ---")
        train_texts = df.loc[train_idx, "text"].tolist()
        val_texts = df.loc[val_idx, "text"].tolist()
        test_texts = df_test["text"].tolist()

        train_labels = df.loc[train_idx, "label"].tolist()
        val_labels = df.loc[val_idx, "label"].tolist()

        train_dataset = TextDataset(train_texts, train_labels, tokenizer)
        val_dataset = TextDataset(val_texts, val_labels, tokenizer)
        test_dataset = TextDataset(test_texts, labels=None, tokenizer=tokenizer)

        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collator)
        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collator)
        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collator)

        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=NUM_CLASSES).to(device)
        optimizer = AdamW(model.parameters(), lr=LR)
        total_steps = len(train_loader) * EPOCHS
        scheduler = get_linear_schedule_with_warmup(optimizer, 0, total_steps)
        scaler = GradScaler()

        for epoch in range(EPOCHS):
            loss = train_fn(model, train_loader, optimizer, scheduler, scaler)
            print(f"Epoch {epoch + 1} Loss: {loss:.4f}")

        val_probs = eval_fn(model, val_loader)
        oof_preds[val_idx] = val_probs

        test_probs = eval_fn(model, test_loader)
        test_preds += test_probs / skf.n_splits

    print(f"OOF Log Loss ({model_name}):", log_loss(true_labels, oof_preds))
    print(f" OOF Accuracy ({model_name}):", accuracy_score(true_labels, np.argmax(oof_preds, axis=1)))

    model_key = model_name.replace("/", "-")
    np.save(f"{SAVE_DIR}/oof_{model_key}.npy", oof_preds)
    np.save(f"{SAVE_DIR}/test_{model_key}.npy", test_preds)

    final_test_preds += test_preds / len(MODELS)

label_map = LabelEncoder().fit(df["author"])
submission = pd.DataFrame({
    "id": df_test["id"],
    "EAP": final_test_preds[:, label_map.transform(["EAP"])[0]],
    "HPL": final_test_preds[:, label_map.transform(["HPL"])[0]],
    "MWS": final_test_preds[:, label_map.transform(["MWS"])[0]],
})
submission.to_csv("submission_llm_ensemble.csv", index=False)
print("\n✅ Submission saved to submission_llm_ensemble.csv")

!pip install catboost

#reimports
import os
import numpy as np
import pandas as pd
from sklearn.metrics import log_loss, accuracy_score
from sklearn.model_selection import StratifiedKFold
from sklearn.calibration import CalibratedClassifierCV
from catboost import CatBoostClassifier
import glob

NUM_CLASSES = 3
SAVE_DIR = "llm_preds"
SUBMIT_PATH = "submission_stacked_calibrated.csv"
SEED = 42
CALIBRATE = True

oof_files = sorted(glob.glob(os.path.join(SAVE_DIR, "oof_*.npy")))
test_files = sorted(glob.glob(os.path.join(SAVE_DIR, "test_*.npy")))

X_train = np.hstack([np.load(f) for f in oof_files])
X_test = np.hstack([np.load(f) for f in test_files])

y_train = df["author"].map({"EAP": 0, "HPL": 1, "MWS": 2}).values
ids = df_test["id"]

oof_meta = np.zeros((len(X_train), NUM_CLASSES))
test_meta = np.zeros((len(X_test), NUM_CLASSES))

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)
for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):
    X_tr, X_val = X_train[train_idx], X_train[val_idx]
    y_tr, y_val = y_train[train_idx], y_train[val_idx]
    y_tr = y_tr.astype(int)
    y_val = y_val.astype(int)

    model = CatBoostClassifier(
        iterations=1000,
        learning_rate=0.03,
        depth=4,
        loss_function='MultiClass',
        random_seed=SEED,
        early_stopping_rounds=50,
        verbose=0
    )

    if CALIBRATE:
        base = CatBoostClassifier(
            iterations=1000,
            learning_rate=0.03,
            depth=4,
            loss_function='MultiClass',
            random_seed=23,
            early_stopping_rounds=50,
            verbose=0
        )
        base.fit(X_tr, y_tr, eval_set=(X_val, y_val))

        model = CalibratedClassifierCV(base, method='isotonic', cv=5)  
        model.fit(X_val, y_val)
    else:
        model = CatBoostClassifier(
            iterations=1000,
            learning_rate=0.03,
            depth=4,
            loss_function='MultiClass',
            random_seed=SEED,
            early_stopping_rounds=50,
            verbose=0
        )
        model.fit(X_tr, y_tr, eval_set=(X_val, y_val))


    oof_meta[val_idx] = model.predict_proba(X_val)
    test_meta += model.predict_proba(X_test) / skf.n_splits

print("\n📊 Stacked Log Loss:", log_loss(y_train, oof_meta))
print("📈 Stacked Accuracy:", accuracy_score(y_train, np.argmax(oof_meta, axis=1)))

submission = pd.DataFrame({
    "id": ids,
    "EAP": test_meta[:, 0],
    "HPL": test_meta[:, 1],
    "MWS": test_meta[:, 2]
})
submission.to_csv(SUBMIT_PATH, index=False)

print(f"\n✅ Submission saved to {SUBMIT_PATH}")

